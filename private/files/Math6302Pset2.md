---
layout: post
title: Math 6302 Pset 2
last_updated: 2025-05-28
---

[comment]: THIS FILE IS AUTOMATICALLY GENERATED FROM Math6302Pset2.tex. IT WILL BE REWRITTEN ON CHANGE OF THE .tex FILE!

> **Problem:**
>
> > **Subproblem:**
> >
> > Now since there are $n+1$ vectors in a series of vectors of rank $n$
> > implies since there for any point in the lattice it can be created
> > with
> > $$n_1 \hat b_1+\cdots+n_{i-1}\hat b_{i-1}+n_{i+1}\hat b_{i+1} + \cdots + n_{n+1} \hat b_{n+1}$$
> >
> > Now since by definition a lattice of rank $n$ is created by $n$
> > basis vectors and this set of vectors is a basis for the lattice,
> > then there will exist some basis vector such that removing it sitll
> > generates the lattice. Let this vector be $b_i$. Now given $n_i b_i$
> > since $n_i b_i \in \mathcal{L}$, there is some equivalent
> > construction
> > $n_1 \hat b_1+\cdots+n_{i-1}\hat b_{i-1}+n_{i+1}\hat b_{i+1} + \cdots + n_{n+1} \hat b_{n+1}$
> > since
> > $$\forall p\in\mathcal{L},\,\exists n_1,\cdots n_{i-1},n_{i+1},\cdots,n_{n+1}$$
> > $$n_1 \hat b_1+\cdots+n_{i-1}\hat b_{i-1}+n_{i+1}\hat b_{i+1} + \cdots + n_{n+1} \hat b_{n+1} = p$$
> >
> > This implies that there are a set of integers such that
> > $$n_1 \hat b_1+\cdots+n_{i-1}\hat b_{i-1}+n_{i+1}\hat b_{i+1} + \cdots + n_{n+1} \hat b_{n+1} = n_i\hat b_i$$
> > which is the same thing as saying
> > $$n_1 \hat b_1+\cdots+n_{i-1}\hat b_{i-1}+n_{i+1}\hat b_{i+1} + \cdots + n_{n+1} \hat b_{n+1} - n_i\hat b_i =0$$
> >
> > and thus we have showed a set of integers such that the linear
> > combination of them is equal to 0. Now since the integers is a
> > subset of the rational numbers implies that we have a set of
> > rational numbers such that $$\sum_{i=1}^{n+1}q_i \hat b_i = 0$$
> > which directly implies $\mathbb{Q}$-linear dependence.
>
> > **Subproblem:**
> >
> > Now since $b_{n+1}\in \mathrm{span}(b_1,\cdots,b_n)$ implies there
> > exists $\hat c\in \mathbb{R}^n$ such that
> > $$b_{n+1}= \sum_{k=1}^i c_k b_k$$ And thus rearranging
> > $$b_i = \frac1{c_i} \lvert ab(b_{n+1}- \sum_{k=1}^{i-1} c_k b_k \rvert$$.
> >
> > Now this implies since span is the set of linear combination of all
> > the vectors, given
> > $\forall \hat t \in\mathrm{span}(b_1,\cdots,b_i)$, let
> > $$\hat t = \sum_{k=1}^i a_i k_i$$ for any aribtary coefficents
> > $c_i\in \mathbb{R}$. Which is guarenteed to exist by definition of
> > span. Then $$\hat t = \sum_{k=1}^i a_k b_k =$$
> > $$\sum_{k=1}^{i-1}a_k b_k + a_i b_i = \sum_{k=1}^{i-1}a_k b_k + a_i(\frac1{c_i} \lvert ab(b_{n+1}- \sum_{k=1}^{i-1} c_k b_k \rvert)$$
> > Which consists of a linear sum of vectors entirely inside of
> > $\mathrm{span}(b_1,\cdots,b_{i-1},b_{n+1})$ and thus any vector in
> > $\mathrm{span}(b_1,\cdots,b_i)$ can be represetned by a sum of
> > vectors in $\mathrm{span}(b_1,\cdots,b_{i-1},b_{n+1})$. Which
> > implies it is in that span.
> >
> > Now suppose
> > $\forall \hat v\in \mathrm{span}(b_1,\cdots,b_{i-1},b_{n+1})$. Then
> > there is guarenteed by definition of span to exist some combination
> > $$\hat v = a_{n+1} b_{n+1}+ \sum_{k=1}^{i-1} a_k b_k$$ Then
> > $$= a_{n+1}\sum_{k=1}^i c_k b_k + + \sum_{k=1}^{i-1} a_k b_k$$ Which
> > consists of a linear sum of vectors entirely inside of
> > $\mathrm{span}(b_1,\cdots,b_i)$ and thus any vector in
> > $\mathrm{span}(b_1,\cdots,b_{i-1},b_{n+1})$ can be represetned by a
> > sum of vectors in $\mathrm{span}(b_1,\cdots,b_i)$. Which implies it
> > is in that span.
> >
> > Thus we have proved both directions so it implies a vector in one
> > span can be represetned in the other span so we proved equality
> > $$\mathrm{span}(b_1,\cdots,b_i)=\mathrm{span}(b_1,\cdots,b_{i-1},b_{n+1})$$
>
> > **Subproblem:**
> >
> > Now given the procedure listed above as assume initally that
> > $b_1,\cdots,b_n$ are linearly independent. Then at each procedure
> >
> > 1.  Size reduction: This step does not affect set of vectors from
> >     $b_1,\cdots b_n$.
> >
> > 2.  Output step: This step doesnt change the set of vectors so it
> >     keeps them independent
> >
> > 3.  Swap: Now since the only vector we are changing is between $b_i$
> >     and $b_{n+1}$ and we start with a set that is linearly
> >     independent the rest of the elements will remain linearly
> >     independent. Now when we switch elemnts, it implies that
> >     $\mu_{i, n+1}\neq 0$ otherwise the algorithm would have
> >     terminated. This implies that there is a part of the sized
> >     reduced $b_{n+1}$ that is in the part of the vector $b_i$ and
> >     not in the rest of the vectors. This implies linear independence
> >     for this step.
> >
> > 4.  Repeat: Since any repetition step consists of the first 3 steps
> >     and we showed the first 3 steps keep the set linearly
> >     independent any repetition will also keep the set linearly
> >     independent
> >
> > Thus since we assumed the base case which is that $b_1,\cdots,b_n$
> > is linearly independent and at every step in the algorithm each step
> > keeps $b_1,\cdots,b_n$ linearly independent implies by induction
> > that at every step of the procedure the vector set remains lienarly
> > independent.0◻
>
> > **Subproblem:**
> >
> > Now to show this program never terminates since this program only
> > terminates when $b_{n+1}=0$, we must show that $b_{n+1}$ never
> > equals $0$.
> >
> > Now since we assume we start with $\mathbb{Q}$ linear independence
> > implies that we cannot write one vector as the sum of linear
> > $\mathbb{Q}$ coefficents with the rest of the vectors such that no
> > vector can be the zero vector, otherwise we could write it as the
> > sum of vectors with coefficent $0\in\mathbb{Q}$. We also showed that
> > the vectors $b_1,\cdots b_n$ are always $\mathbb{R}$ linearly
> > independent throughout theh algorithm. This inherently implies
> > $\mathbb{Q}$ linear independence. Now since all vectors start not
> > $0$ and process $3$ is simply a swap, the only way they could ever
> > change in value could is in process 1. Now since the size reduction
> > operation consists of adding integer multiples of the basis, this
> > operation does not change the linear independence of $\mathbb{Q}$.
> > Thus the vectors are always $\mathbb{Q}$ independent. Now suppose
> > all vectors are $\mathbb{Q}$ independent in the set
> > $b_1,\cdots,b_i,b_{n+1}$. Then this implies that $b_{n+1}$ can never
> > be 0 since otherwise i could be made out of sum of vectors with
> > coefficent 0. Thus since at every step the whole set is $\mathbb{Q}$
> > lineraly indepenent even on the size reduction step the values of
> > the vectors will never be $0$ and thus the program will never
> > terminate.
>
> > **Subproblem:**
> >
> > We define $$\Phi= \Pi^n_{i=1}\lvert  \rvert\tilde{b_i}||$$ Then
> > before the swap step let the set be $\{b_1,\cdots b_n+1\}$ which
> > implies that the vectors after teh swap step will be written as
> > $\{b_1,\cdots,b_{i-1}, b_{n+1}, b_{i+1}, \cdots, b_n, b_i\}$. Then
> > let $\Phi'$ be $\Phi$ after the swap step. Then
> > $$\frac{\Phi'}\Phi= \frac{\Pi^n_{k=1}\lvert  \rvert\tilde{b_k'}||}{\Pi^n_{k=1}\lvert  \rvert\tilde{b_k}||} = \frac{\tilde{b_i'}}{\tilde{b_i}}=\frac{\tilde{b_{n+1'}}}{\tilde{b_i}}$$
> > This is true since from problem 1.2 the span of
> > $b_1,\cdots b_{i-1},b_n$ and $b_1, \cdots b_i$ is equivalent so the
> > ghram schmidt process is the same. Where $\tilde{b_{n+1}}'$ is size
> > reduced such that $\lvert u_{i,n+1} \rvert < \frac12$. Now since the
> > spans of basis $b_1\cdots b_i$ and $b_1 \cdots b_{i-1}, b_n$ are
> > equivalent implies that the ghram schmidt orthogonalization of both
> > leaves the $i$th basis vector ($b_i$ or $b_{n+1}$) equivalent up to
> > a scaling factor. Thus the size reduction
> > $$\lvert \mu_{i,n+1}<\frac12 \rvert \Rightarrow \ab<\tilde b_{n+1}, \tilde b_i> < \frac{\ab<\tilde b_i, \tilde b_i>}2\Rightarrow c < \frac{|\tilde{b_i}|}{2|\tilde{b_i}|}\Rightarrow c < \frac12$$
> > Where $c$ is the scaling factor between the two vectors since they
> > are equivalent. This directly implies $\frac{\Phi'}{\Phi} < \frac12$
>
> > **Subproblem:**
> >
> > Minkowski
>
> > **Subproblem:**
> >
> > We know from 1.5 that every run of the algorithm decreases $\Phi$ by
> > two. Thus since $\Phi$ is guarenteed not to terminate, we know that
> > we can run this algorithm enough to achieve a set of basis pairs
> > that satisfies this property.
> >
> > Now let $i=\log_2(\frac C{(\epsilon/2\sqrt{n})^n})+1$. Then running
> > the algorithm $i$ iterations implies that
> > $$\Phi <\frac C{2^n} < \frac C{\frac C{(\epsilon/2\sqrt{n})^n}+1} < \frac C{\frac C{(\epsilon/2\sqrt{n})^n}}$$
> > Where $C =\Phi'$, or $\Phi$ of the initial basis set. This implies
> > that $\sqrt{n}\Phi^{1/n} < \epsilon$. And thus from 1.7 there exsits
> > $$0 < \lvert  \rverty|| < \sqrt{n}\Phi^{1/n}$$ which implies there
> > exists a vector such taht $$0<\lvert  \rverty||<\epsilon∎$$

> **Problem:**
>
> > **Subproblem:**
> >
> > Let $y_i$ be the coefficents for the linear combination of
> > $\tilde b_i$ gram schmidt basis vectors such that it is equal to
> > $y$. Then $$y_i = z_i + \sum_{k=i+1}^n z_k \mu_{k,i}$$ This implies
> > that $|y_i|\leq 2^{n/2}$. Thus
> > $$|z_i| \leq |y_i| + |\sum_{k=i+1}^n z_k \mu_{k,i}| \leq |y_i| + \frac12\sum_{k=i+1}^n|z_k|$$
> > Directy implies
> > $(\lambda_1(\mathcal{L}))^2 = \sum_{i=1}^n y_i^2 ||\tilde b_i ||^2$.
> > This imples our base case.
> >
> > Now let
> > $|z_{n-k}|\leq |y_{n-k}| + \frac12 \sum_{j=1}^k |z_{n-j}| \leq 2^{n/2} + \frac12\sum_{j=1}^k 2^{n/2}(3/2)^j \leq 2^{n/2}(3/2)^k$
> >
> > Now since our base case satisfies and we showed the recurring step
> > implies that by induction this holds. 0◻
>
> > **Subproblem:**
> >
> > Create an algoritm defined by iterating in order by $i$ through all
> > vectors such that $|z_{n-i}|\leq 2^{n/2+i}, z\neq0$. Then if
> > $||B\hat z||<$current shortest vector then set it as the shortest
> > vector. Then output at the end.
> >
> > Now since we enumerate over $|z_{n-i}|\leq 2^{n/2+i}, z\neq0$, our
> > number of steps is $$\Pi_{i=1}^n  2^{n/2+n-1}= 2^{n^2}$$ which
> > implies a total complexity of $2^{\mathcal{O}(n^2)}$
> >
> > Now since there exists some vector $v$ in the set described such
> > that $Bv = y\in \mathcal{L}$ with $||y||=\lambda_1(\mathcal{L})$ and
> > we are finding it by looping over the set such that we find the
> > smallest one we will find the shortest nonzero vector. Note that it
> > is nonzero since the matrix $B$ spans the space.
>
> > **Subproblem:**
> >
> > subproblem **Part C:**\
> > Proof derived from
> > <https://pubsonline.informs.org/doi/10.1287/moor.12.3.415>, section
> > 4.
> >
> > > **Claim:**
> > >
> > > There exists an algorithm for exact CVP that runs in
> > > $2^{\mathcal{O}(n^2)}$.
> >
> > Recall
> >
> > > **Definition:**
> > >
> > > Given a vector $t\in\mathbb{R}^n$ and lattice
> > > $\mathcal{L}\subset \mathbb{R}^n$
> > > $$CVP(\mathcal{L}, t) = := \min_{y\in\mathcal{L}}\lvert  \rverty-t||$$
> >
> > > **Proposition:**
> > >
> > > Suppose that $\mathcal{L}(b_1,\cdots,b_n)$ is a lattice in
> > > $R^{k}$, $k\geq n$ with all $b_i$ independent and
> > > $b_0\in \mathbb{R}^k$. Let $b_0'$ be the projection of $b_0$ onto
> > > the span of $b_1,\cdots,b_n$. Then there exists a point
> > > $b\in\mathcal{L}$ such that
> > > $$\lvert b-b_0' \rvert \leq \frac12 \lvert ab(\sum_{j=1}^n (b_j(j))^2 \rvert^\frac12$$
> >
> > ::: proof
> > *Proof.* Since $b(1,1), b(n,n)$ forms an orthogonal basis for their
> > vector spcae with $b_0'$ in that vector space, this implies we can
> > successively choose integers with ordering
> > $\alpha_n, \alpha_{n-1},\cdots,\alpha_1$ such that
> > $$\lvert ((\sum_{i=j}^n\alpha_ib_i-b_0'), b(j,j)) \rvert\leq (b_j(j))^2/2\forall j$$
> > is true given arbitary choice of $\alpha_j$. This implies the
> > proposition. ◻
> > :::
> >
> > > **Proposition:**
> > >
> > > There exists a easily determined set
> > > $T\subset \mathcal{L}^{n-i+1}$ with $|T|\leq (n+\sqrt n)^{n-i+1}$
> > > such that if $\sum_{j=1}^n \lambda_jb_j$ is closest in the lattice
> > > to $b_0$ then $(\lambda_i,\cdots,\lambda_n)$ belongs to $T$.
> >
> > ::: proof
> > *Proof.* Now since $$\sum_{j=1}^n\lambda_jb_j=v$$ is one of the
> > cloest (nonunique) points in $\mathcal{L}$ to $b_0$ implies $v$ is
> > the closest point to $b_0'$ in $\mathcal{L}$. Now proposition 0.3
> > implies that $|v-b_0'| \leq (\sqrt{n}/2)b_i(i)$ Yet
> > $|v-b_0'| \geq |((v-b_0'),b(n,n))|/b_n(n)=|\lambda_nb_n(n)-(b_0',b(n,n))/b_n(n)|=|\lambda_n-t|b_n(n)$
> > for some $t\in\mathbb{R}$. This implies at most
> > $1+\sqrt{n}b_i(i)/b_n(n)$ candidates for $\lambda_n$. This implies
> > we can show a similar bound for $\lambda_1,\cdots,\lambda_n$ using
> > (TODO). Now suppose $\lambda_{j+1},\cdots,\lambda_n$ are fixed
> > integers, $j\geq i+1$. Then this implies by (TODO) that there are at
> > most $1+\sqrt n b_i(i)/b_j(j) \leq (1+\sqrt n)b_i(i)/b_j(j)$
> > possible values of $\lambda_j\ \text{s.t.} \ $ the length of
> > $v-b_0'$ in direction of $b_j(j)$ is boudned by
> > $\frac{\sqrt n}2 b_i(i)$. This since $b_i(i)\geq b_j(j)$ that given
> > a set $T$ candidate $\lambda_1,\cdots,\lambda_n$ we get
> > $$|T|\leq \Pi_{j=1}^n (1+\sqrt n)b_i(i)/b_j(j)$$ So this implies
> > that $b_i(i)$ is the length of the shortest vector in $\mathcal{L}$
> > 0◻ ◻
> > :::
> >
> > > **Theorem:**
> > >
> > > CVP solves for the closest vector in $\mathcal{O}(n^ns)$
> > > arithmetic operations where $s$ is the length of the inupt
> >
> > ::: proof
> > *Proof.* Now let $T(n)$ bet he number of arithmetic operations
> > performed by $CVP$. Then
> > $$T(n)\leq (n+\sqrt n)^{n-1+1}T(i-1)+q(n),$$ $q(n)$ is a polynomial
> > with no $s$ dependence. This implies that betwee $1\leq i\leq n$,
> > $$\max(((i-1)/(n+\sqrt n))^{i-1})$$ occurs at $i=n$ and
> > $$\lim ((n-1)/n)^{n-1}=\frac1e.$$ This implies that $T(n)$ is
> > $\mathcal{O}(n^n)$ by inducting over $n$. This implies that
> > $T(n) = \mathcal{A}_0(n)+\mathcal{A}_1(n)$ where
> > $\mathcal{A}_0(n), \mathcal{A}_1(n)$ represent the number of
> > oeprations required for $\mathcal{A}_0,\mathcal{A}_1$. Thus since
> > max time complexity between the two algorithms is
> > $\mathcal{A}_0(n)=\mathcal{O}(n^n)$ implies that this is the time
> > complexity of the algorithm. 0◻. ◻
> > :::
> >
> > ```python
> > A0(n, L):# aka shortest 
> >           if n=1 
> >             return [L[1]]
> >           L = LLL(L) #LLL reduce the basis
> >           def: LProjGoto
> >           LProject
> >           for i in range(i):
> >             LProject[i] = Project(B[i], L-{L[i]})
> >           LNew = A0(n-1, LProject)
> >           for i in range(2,n)
> >             Lift(Lnew[i], L[i])
> >           if Norm(L[2]) < sqrt(3)*Norm(L[2])/2: 
> >             Swap(L[1],L[2])
> >             Goto LProjGoto 
> >           for i in range j
> >             if Norm(L[j] >= L[1]):
> >               j0 = min j such that its true 
> >             else: 
> >               j0 = n+1 
> >           for i in range(1, j0-1):
> >           LBasis.append(Lnew[i])
> >           Enumerate(Basis)# enumerates the basis 
> >
> >           return: a basis L containing v_1 
> > ```
> > ```
> >         A1() 
> > ```
> > ```
> >         CVP(n L):
> >           NewBasis = A0(L)
> >           Candidates = null
> >           forall lambda i: 
> >             if i = 1 
> >               a1 = 
> >
> > ```

> **Problem:**
>
> > **Subproblem:**
> >
> > Now suppose that $r= \max_{t\in\mathbb{R}^n}(t,\mathcal{L})$. Then
> > for any point $t\in\mathbb{R}^n$, it is always at most $r$ away from
> > any point in the lattice. Now since any volume ball of radius $r$
> > will contain all the points at most $r$ distance away from it
> > implies that any volume balls around every set of lattice points
> > will contain all points in $\mathbb{R}^n$. Thus
> > $\max_{t\in\mathbb{R}^n}\text{dist}(t,\mathcal{L})\in \{r|\mathcal{L}+B^n(r)=\mathbb{R}^n\}$
> >
> > Now suppose $r'<\max_{t\in\mathbb{R}^n}(t,\mathcal{L})$. Then since
> > $r'$ is less than the maximum distance from the lattice to any
> > point, there exists a point $p\in\mathbb{R}^n$ such that the
> > distance from $p$ to any point in the lattice is greater than $r'$.
> > This then directly implies that there exists a point not in
> > $\mathcal{L}+B^n(r)$ which implies that
> > $\mathcal{L}+B^n(r)\neq\mathbb{R}^n$. Thus $r'$ is not in the set
> > $\{r|\mathcal{L}+B^n(r)\}=\mathbb{R}^n$.
> >
> > Thus we have showed that
> > $\max_{t\in\mathbb{R}^n}\text{dist}(t,\mathcal{L})\in \{r|\mathcal{L}+B^(n)=\mathbb{R}^n\}$
> > and that given
> > $r'<\max_{t\in\mathbb{R}^n}\text{dist}(\hat t, \mathcal{L})$ then
> > $r'\notin \{r|\mathcal{L}+B^n(r)=\mathbb{R}^n\}$. Thus
> > $$\max_{t\in\mathbb{R}^n}\text{dist}(t,\mathcal{L})= \min\{r|\mathcal{L}+B^n(r)=\mathbb{R}^n\}∎$$
>
> > **Subproblem:**
> >
> > Let
> > $$S_r := \cup_{y\in \mathcal{L}\cap B^n(r)}(B^n(\mu(\mathcal{L}))+1), r \geq \mu(\mathcal{L})$$
> > Then sicne they are disjoint implies that
> > $$\text{vol}(B^n(\mu(\mathcal{L})))(\mathcal{L}\cap B^n(r))\geq \text{vol}(S_r)$$
> >
> > But since any distance in the lattice is bounded by
> > $\mu(\mathcal{L})$ implies that
> > $$\forall v\in B^n(r-\mu(\mathcal{L}))$$ there exists a point such
> > that $v=x+y$ where $x\in \mathcal{L}$ $y\in B^n(\mu(\mathcal{L}))$.
> > Thus since $||v|| +||x|| <r$ implies by triangle inequality that
> > $||v|| < r$.
> >
> > This implies that all
> > $\forall v\in B^n(r-\mu(\mathcal{L})), v\in S_r$. Thus since
> > $$B^n(r-\mu(\mathcal{L})) \leq \text{vol}(B^n(\mu(\mathcal{L}))) (\mathcal{L}\cap B^n(r))$$
> > implies that $$\frac{B^n(r-\mu(
> > \mathcal{L}
> > ))}{\mathcal{L}\cap B^n(r)}\leq \text{vol}(B^n(\mu(\mathcal{L})\forall r$$
> > Thus
> > $$\lim_{r\to\infty}\frac{B^n(r-\mu(\mathcal{L}))}{\mathcal{L}\cap B^n(r)} = \frac{B^n(r)}{\mathcal{L}\cap B^n(r)} = \text{det}(\mathcal{L})$$
> > Which we just showed is less than
> > $\mathrm{vol}(B^n(\mu(\mathcal{L})))$. Thus
> > $$\text{det}(\mathcal{L}) \leq \mathrm{vol}(B^n(\mu(\mathcal{L})))$$
>
> > **Subproblem:**
> >
> > Suppose this is false. Then there must exist some coefficent less
> > than $\frac{\lambda_n(\mathcal{L})}2$ such that it is equal to
> > $\mu(\mathcal{L})$.\
> > \
> > Now for a given set of
> > $\lambda_1(\mathcal{L})\cdots \lambda_n(\mathcal{L})$ find a working
> > configuration of associated vectors for this set of lattices. This
> > is guarenteed to exist since if you sort the vectors
> > $\mathbf{y}_1,\cdots,\mathbf{y}_n$ by norm and sort in arbitrary
> > order for vectors of equivalent norm, then for each $1\leq i\leq n$
> > the definiition satisifies and you have an associated $\mathbf{y}_i$
> > for every $\lambda_i(\mathcal{L})$. Associate each basis vector
> > associated with $\lambda_i(\mathcal{L})$ as $\mathbf{y}_i$\
> > \
> > Now define a new lattice $\mathcal{L}'$ as the set of basis vectors
> > $\{\mathbf{y}_1,\cdots,\mathbf{y}_{n-1}, \frac12\cdot\mathbf{y}_n\}$.
> > Now since $\mathbf{y}_1,\cdots,\mathbf{y}_n$ are linearly
> > independent imply $\mathbf{y}_1,\cdots,\mathbf{y}_{n-1}$ is also
> > linearly independent. Recall from the definition of linear
> > indepndence on the reals that no set of coefficents
> > $\hat c\in\mathbb{R}^n$ where
> > $\sum^{n-1}_{i=1} c_i \hat v_i = c_n v_n$. This directly implies
> > that no set of sum of linear real coefficents of
> > $\mathbf{y}_1,\cdots,\mathbf{y}_{n-1}$ can be equal to any vector in
> > the linear span of $\frac12\cdot \mathbf{y}_n$. This directly
> > implies since the integers are a subset of the reals that no sum of
> > integer coefficents for $\mathbf{y}_1,\cdots,\mathbf{y}_{n-1}$ can
> > reach point $\frac12\cdot\mathbf{y}_n$ without using vector
> > $\frac12\cdot\mathbf{y}_n$ in its sum. Now since $\mathcal{L}'$ is a
> > lattice, the all its coefficents must be integers which implies that
> > since we need to use at least $\pm 1 \cdot \frac12\cdot\mathbf{y}_y$
> > to reach $\frac12\cdot\mathbf{y}_n$ from any point in the linear
> > span of $\mathbf{y}_n-\{\vec0\}$, using the triangle inequality we
> > get a bound on the norm of the vector to reach any lattice point in
> > the span of $\frac12\cdot\mathbf{y}_n$ point of
> > $\frac12\lambda_n(\mathcal{L})$.\
> > \
> > Now going back to $\mathcal{L}$, since they differ by a scaling
> > factor on a single vector, we know that the only difference between
> > the set of lattice vectors is that $(n+\frac12)\mathbf{y}_n$ is in
> > $\mathcal{L}'$ but not in $\mathcal{L}$. Since we know a bound on
> > the distance to $\frac12\mathbf{y}_n$, $\mathcal{L}'$ implies that
> > we know there is a point at least $\frac12\lambda_n(\mathcal{L})$
> > away from any point on the lattice, for there to be a
> > $r|\mathcal{L}+B^n(r)=\mathbb{R}^n$, $r$ must be at least
> > $\frac12\lambda_n(\mathcal{L})$. This implies a bound on the
> > $\frac12\lambda_n(\mathcal{L})\leq\min\{r|\mathcal{L}+B^n(r)=\mathbb{R}^n\} = \mu(\mathcal{L})$
> > which implies the bound. 0◻

> **Problem:**
>
> > **Subproblem:**
> >
> > > **Definition:**
> > >
> > > Defined in (5.3)
> > > $$\sum_{y\in\mathcal{L}}f(\mathbf{y}-\mathbf{t}) = \frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}\sum_{w\in\mathcal{L}^*}\cos(2\pi\ab<\mathbf{w},\mathbf{t}>\hat f(\mathbf{w}))$$
> >
> > Now given
> > $$\rho_s(\mathcal{L}):= \sum_{\mathbf{y}\in\mathcal{L}}\rho_s(\mathbf{y}) = \sum_{\mathbf{y}\in \mathcal{L}} e^{-\pi \lvert  \rvert\mathbf{y}||^2/s^2}$$
> > Setting $\mathbf{t}=0$ implies that
> > $$\sum_{y\in\mathcal{L}}f(\mathbf{y}) = \frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}\sum_{w\in\mathcal{L}^*}\cos(2\pi\ab<\mathbf{w},\mathbf{0}>\hat f(\mathbf{w}))= \frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}\sum_{w\in\mathcal{L}^*}\hat f(w)$$
> > and since the determinant of the lattice is defined as 1,
> > $\frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}=1$. Thus
> > $$\sum_{y\in\mathcal{L}}f(\mathbf{y}) = \frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}\sum_{w\in\mathcal{L}^*}\cos(2\pi\ab<\mathbf{w},\mathbf{0}>\hat f(\mathbf{w}))= \frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}\sum_{w\in\mathcal{L}^*}\hat f(w)$$
> > We also know that the gaussian function is equivalent up to a
> > scaling factor, i.e.
> > $\hat \rho_s(\mathbf{w})=s^n\rho{\frac1s}(\mathbf{w})$
> >
> > So applying the posson summation formula to the guassian function
> > and using its scaling property implies that
> > $$\rho_s(\mathcal{L})=\sum_{y\in\mathcal{L}}\rho_s(y) = \frac1{\begin{vmatrix}\mathcal{L}\end{vmatrix}}\sum_{w\in\mathcal{L}^*} \hat \rho(w) = \sum_{w\in\mathcal{L}^*}s^n \rho_{1/s}(w)$$
> > $$=s^n\rho_{1/s}(0)+\sum_{w\in\mathcal{L}-\{0\}}\rho_{1/s}(w) \geq s^n$$
> > since $\rho_{1/s}$ and $s$ are positive values.0◻
>
> > **Subproblem:**
> >
> > Recall that
> > $$\rho_{s,r}(\mathcal{L})\leq e^{-\pi x^2}\rho_s(\mathcal{L})$$
> > where $r=\sqrt{\frac n{(2\pi)}}s+xs$ and $x\geq 0$. Thus since
> > $x=10\geq0$ implies that we know
> > $$\rho_{s,r}(\mathcal{L})\leq e^{-\pi 100}\rho_s(\mathcal{L})$$ Now
> > since we know that $\rho_s(\mathcal{L})\geq 2$ implies that given
> > $$e^{-\pi100}\rho_{s,r}(\mathcal{L})<\rho_s(\mathcal{L})-1$$ thus
> > $$\rho_{s,r}(\mathcal{L})< e^{100\pi}(\rho_s(\mathcal{L})-1)$$
> >
> > Directly implies that
> > $$\rho_{s,r}(\mathcal{L})\leq e^{-\pi100}\rho_s(\mathcal{L})< \rho_s(\mathcal{L})-1$$
> > that $\rho_{s,r}(\mathcal{L}) < \rho_s(\mathcal{L})-1$. 0◻
>
> > **Subproblem:**
> >
> > Now let $$s(n) := 1+\frac {2n}{\sqrt{n/(2\pi)}}$$ Then since 4.1
> > shows $$\rho_s(\mathcal{L}) \geq s^n \forall s>0$$ Then it will hold
> > that $$s(n)^n \geq 1+\frac 2{\sqrt{n/(2\pi)}}$$ regardless of the
> > $n$ dependence on $s$.
> >
> > Now since
> > $$1+\frac {2n}{\sqrt{n/(2\pi)}} \geq 1+\frac {2(n-1)}{\sqrt{(n-1)/(2\pi)}}$$
> > is equivalent to $\sqrt n \geq \sqrt{(n-1)}$ which is trivially true
> > given $n>1$ then $s(n) \leq s(n-1)$ for $n>1$.
> >
> > And since $s(1)=2$ implies $s(n)\geq 2\forall n$.
> >
> > Thus since $$\rho_{s,r}(\mathcal{L}) < \rho_s(\mathcal{L})-1$$
> > implies that
> >
> > And since $\lambda_1(\mathcal{L})\leq r$ implies that since we know
> > $\rho_{s,r}(\mathcal{L}) < \rho_s(\mathcal{L})-1$ and
> > $$\rho_s(\mathcal{L}) = \rho_{s,r}(\mathcal{L}) + \sum_{y\in \mathcal{L}\cap B^n(r)}\rho_s(y)$$
> > That $\sum_{y\in \mathcal{L}\cap b^n(r)}\rho_s(y) > 1$ which implies
> > that $\sum_{y\in \mathcal{L}\cap b^n(r)-\{0\}}\rho_s(y) > 0$ Which
> > means that since the sum of the fourier components is geq 0 then
> > there must exist a vector in the lattice such taht $||y||<r$.
> >
> > $$\lambda_1(\mathcal{L}) \leq r = (1+\frac2{\sqrt{n/(2\pi)}})(\sqrt{\frac{n}{2\pi}}+10) < \sqrt{\frac{n}{2\pi}}+100$$
> >
> > Shows that $\lambda_1(\mathcal{L})\leq \frac n {2\pi}+100$

> **Problem:**
>
> A bit
